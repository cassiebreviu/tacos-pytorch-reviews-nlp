{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "gather": {
     "logged": 1612453335201
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.20.0\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment, ScriptRunConfig, Environment, Dataset, Datastore, ComputeTarget, ScriptRunConfig\n",
    "import os\n",
    "import azureml.core\n",
    "from azureml.pipeline.steps import PythonScriptStep,EstimatorStep\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "import pandas as pd\n",
    "from azureml.data.datapath import DataPath\n",
    "import azureml.mlflow\n",
    "import mlflow\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1612453339033
    }
   },
   "outputs": [],
   "source": [
    "# get workspace\n",
    "workspace = Workspace.from_config()\n",
    "\n",
    "# get compute target\n",
    "compute_target = workspace.compute_targets['gandalf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conda_dependencies.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conda_dependencies.yml\n",
    "\n",
    "dependencies:\n",
    "- python=3.6.8\n",
    "- pip:\n",
    "  - azureml-core==1.18.0.post1\n",
    "  - azureml-defaults==1.18.0\n",
    "  - azureml-telemetry==1.18.0\n",
    "  - azureml-train-restclients-hyperdrive==1.18.0\n",
    "  - azureml-train-core==1.18.0\n",
    "  - cmake\n",
    "  - torch\n",
    "  - mkl\n",
    "  - future\n",
    "  - numpy\n",
    "  - scikit-learn\n",
    "  - pandas\n",
    "  - matplotlib\n",
    "  - torchtext\n",
    "  - azureml-mlflow\n",
    "  - mlflow\n",
    "  - azureml-contrib-fairness\n",
    "  - fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "gather": {
     "logged": 1612453348746
    }
   },
   "outputs": [],
   "source": [
    "# From a Conda specification file\n",
    "env = Environment.from_conda_specification(name = \"PyTorch-NLP-GPU-V1\",\n",
    "                                             file_path = \"conda_dependencies.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"name\": \"tacoreviews\",\n",
       "  \"container_name\": \"tacoreviews\",\n",
       "  \"account_name\": \"haldatasets\",\n",
       "  \"protocol\": \"https\",\n",
       "  \"endpoint\": \"core.windows.net\"\n",
       "}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get reviews datastore (where all the output datasets will live)\n",
    "datastore = Datastore.get(workspace, 'tacoreviews')\n",
    "datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload dataset from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark or pandas dataframe\n",
    "dataset_pandas = Dataset.Tabular.register_pandas_dataframe(pandas_df, danlp-sentiment-reviews-traintastore, \"new_ds_from_pandas\", show_progress=True)\n",
    "\n",
    "#or upload from local direcotry\n",
    "uploaded_directory = Dataset.File.upload_directory(src_dir='weather-data/', target=DataPath(adls_datastore, 'dv_lake_store_101/'), show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacoreviews_ds = Dataset.get_by_name(workspace, 'tacoreviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('tacoreviews', 'source/')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"74d497e8-b074-4870-9768-f01eca1b4f8c\",\n",
       "    \"name\": \"tacoreviews\",\n",
       "    \"version\": 2,\n",
       "    \"description\": \"Sample reviews we might get for our restaurant!\",\n",
       "    \"workspace\": \"Workspace.create(name='hal', subscription_id='91d27443-f037-45d9-bb0c-428256992df6', resource_group='robots')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tacoreviews_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Step\n",
    "1. Define OutputDataset\n",
    "2. Define Script Run\n",
    "3. Define Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.data.output_dataset_config.OutputFileDatasetConfig at 0x7fd18b3c5e48>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output Dataset\n",
    "prep_ds = OutputFileDatasetConfig(destination=(datastore, 'prep/{run-id}')).register_on_complete(name='tacoreviewsprep')\n",
    "prep_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prep step configuration\n",
    "prep_src = ScriptRunConfig(\n",
    "    source_directory='.',\n",
    "    script='prepare.py',\n",
    "    compute_target=compute_target,\n",
    "    environment=env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prep step\n",
    "prepStep = PythonScriptStep(\n",
    "    script_name=prep_src.script,\n",
    "    name='prepare step',\n",
    "    arguments=['--source_path', \n",
    "               tacoreviews_ds.as_named_input('tacoreviews').as_mount(),\n",
    "               '--target_path', \n",
    "               prep_ds],\n",
    "    #inputs=[tacoreviews_ds],\n",
    "    #outputs=[prep_ds],\n",
    "    runconfig=prep_src.run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.data.output_dataset_config.OutputFileDatasetConfig at 0x7fd18b40eb00>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output Dataset\n",
    "train_ds = OutputFileDatasetConfig(destination=(datastore, 'train/{run-id}')).register_on_complete(name='tacoreviewstrain')\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prep step configuration\n",
    "train_src = ScriptRunConfig(\n",
    "    source_directory='.',\n",
    "    script='train.py',\n",
    "    compute_target=compute_target,\n",
    "    environment=env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prep step\n",
    "trainStep = PythonScriptStep(\n",
    "    script_name=train_src.script,\n",
    "    name='train step',\n",
    "    arguments=['--source_path', \n",
    "               prep_ds.as_input(name='tacoreviewsprep').as_mount(),\n",
    "               '--target_path', \n",
    "               train_ds],\n",
    "    #inputs=[prep_ds],\n",
    "    #outputs=[train_ds],\n",
    "    runconfig=train_src.run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep and Train Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline & run experiment\n",
    "pipeline = Pipeline(workspace, steps=[prepStep, trainStep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step prepare step [ff2ae02e][ae9d6d27-59e2-47b6-8069-d80858ebb6cd], (This step will run and generate new outputs)Created step train step [66f23390][e005cc40-a546-4d1a-b2c1-23a4b35e0731], (This step will run and generate new outputs)\n",
      "\n",
      "Submitted PipelineRun 43560a07-24ba-431d-8e8b-39c206dc5981\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/nlp-sentiment-reviews/runs/43560a07-24ba-431d-8e8b-39c206dc5981?wsid=/subscriptions/91d27443-f037-45d9-bb0c-428256992df6/resourcegroups/robots/workspaces/hal\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment(workspace, 'nlp-sentiment-reviews')\n",
    "run = exp.submit(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Only Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_reviews_ds = Dataset.get_by_name(workspace, name='tacoreviewsprep', version=\"6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prep step\n",
    "trainPipelineStep = PythonScriptStep(\n",
    "    script_name=train_src.script,\n",
    "    name='train step',\n",
    "    arguments=['--source_path', \n",
    "               prepared_reviews_ds.as_mount(),\n",
    "               '--target_path', \n",
    "               train_ds,\n",
    "               '--epochs', \n",
    "               5,\n",
    "               '--learning_rate',\n",
    "               5.0,\n",
    "               '--batch_size',\n",
    "               16],\n",
    "    #inputs=[prep_ds],\n",
    "    #outputs=[train_ds],\n",
    "    runconfig=train_src.run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = Pipeline(workspace, steps=[trainPipelineStep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step train step [eaac105c][790d3a4b-1041-4b66-bd77-9b2beea90bb1], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun e6d1e426-09ea-44fa-85e4-74e9d90af3a9\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/nlp-sentiment-reviews-train/runs/e6d1e426-09ea-44fa-85e4-74e9d90af3a9?wsid=/subscriptions/91d27443-f037-45d9-bb0c-428256992df6/resourcegroups/robots/workspaces/hal\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment(workspace, 'nlp-sentiment-reviews-train')\n",
    "run = exp.submit(train_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
